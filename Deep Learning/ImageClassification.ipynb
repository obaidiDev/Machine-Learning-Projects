{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1704717129690,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"OvmBbY_QCi8X"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":7632,"status":"ok","timestamp":1704717137605,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"5yh23b13CANZ"},"outputs":[],"source":["!echo \"Downloading 101_Object_Categories for image notebooks\"\n","\n","!curl -L -o 101_ObjectCategories.zip --progress-bar https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip?download=1\n","!unzip 101_ObjectCategories.zip\n","!mv caltech-101/101_ObjectCategories.tar.gz ./101_ObjectCategories.tar.gz\n","!tar -xzf 101_ObjectCategories.tar.gz\n","!rm 101_ObjectCategories.tar.gz\n","!ls\n","\n","clear_output()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1704717137605,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"qcew9_0CC2TS"},"outputs":[],"source":["import random\n","\n","import torch\n","from torch.utils.data import Subset\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1704717137605,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"RUqAyJFQC283"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToTensor(), transforms.Resize((64, 64), interpolation=transforms.InterpolationMode.NEAREST)\n","])\n","\n","image_dataset = torchvision.datasets.ImageFolder(root='101_ObjectCategories', transform=transform)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1704717137605,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"EI8MHAqcD4go","outputId":"4dc9fe8f-954e-4bf2-c804-0ace6fd2e519"},"outputs":[{"name":"stdout","output_type":"stream","text":["9144\n"]}],"source":["print(len(image_dataset))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1704717137605,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"W0vQyvmGD_kQ","outputId":"637cdedb-3b1b-4244-afc3-4f562af89c09"},"outputs":[{"name":"stdout","output_type":"stream","text":["label=0\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAgfklEQVR4nKV6d3hc1Zn3qbfMvdNHZdS75Sa5YMsYAzYQTBICbAoEU9O/kCUFkm+TEGA3QEhIlk3bEBIgJLupBFLp1RhsjAs2xsaWLdvqGklT75RbTtk/rjQWJHmy5Tx69NyZOfe8v7e/55wXJmJxCCGEEAAAAMAY+88QQiklAAAhhBDCmEIINU3jnHPOEUIQQoSQP2d+CACAEML/CQBAKZVSCiE8z6OUMsaEAAghjLGUUlVVx3E45xBCIQSE0p+MEBJCAAA45z6AUwSE8LExxvy3iI+4ShIAUMXkf4Pmhz9NSokx9qFzzlVVra7rv1clDwBgjPkPiqL4/ACAfJSUUp+rquCEYD7phWD8j1US1eGLACFE/CeMsQ+9ukT1v5TSh+7jxhgLIQghPnr/FZ8fn4Hqav5/nzYhxPM8fxFfxlJKQoiU0ucEY+wr0J/jeZ4vtYUCreKpAoAQEn8t/7/PDPhrwwfqa0DTNCGED6XKoQ/LnyClRAAIxnwl6LqOIAQYc84xgBhhf75YwJ6/vJQSQgwAAgBhTF3XRQgBIKsmjRABAGAMhBD+M/FZ+Vu4F5oQQqhSqfhKr4Ku8uzbgO8APj3fEiilGGPXdSGElFJKqJTSdV1KKcDIcRxFUaSUvsirAvap+IwtNJuFhuQTmlNEdbyNk6ot+m/6ihJCVPXoS9136+pkz/MUVUUIcc59EJqmeZ4npWSMSSmroH0P9E3Al6O/lE+uGg98efmgfVX7dBljxA8v/hBCzEcjn8WFLuXHIhwIBMrlctWHqj5Q5VYIoes6xZgx5tt3FRAhRPBTgc7QdM/zCCFCCIlJya4oimLbdtV/fNFUMfjsVUnPOdJC8S90lIXeI6X0DZFz7rqu/35Vcgtcf05pnHMMoT+/qpmFIqyqFGPsQxRC+CGhatK+kuH8Oj4S/1dFUfw5EEJSlXf1h4XQ//JZCOHHdUKILzxfwPMGKDHGfpD2fwXzgWXuZwgppb7251jF2BcKwKgq+6rN+M8L7ZOQU5iJb8RVF6ky+pfQq4v60KvRRtFUKSUWnHsOFmGA8/nc0GdvuKq9rnmilH/24Ydr9XM3/8NFpazz7DNPHZkcLAMLK9ApO1xC7noEzkU/zjlBuFKpYIwRwogSy7J8a/HpVpXpC9H/KKUkVRvwMcEFToDQqai60Az8DIoxJoQ4nCkcIAw8Q53OjQVCsfM/sCntipC2tCSsvgtIMHLGbj7c1tmZlP3Hj842B7t2P/lyAuoUYpXQatSvJhbfyx3H8S2qGqmrmlkYGyCEsKuju5oBqsbgx0coefVLhgCGCAEIAIhG45Zl+WERUYIkwFKEV7WctXIdiTUeOL5vYHkftqgeCmCkOoLcdfePNp//jt7uBiAKY7MjLES+ef3n1neuEpwgRZWMIwCFEAxKArjHhCckEh6XQgrIAYRwrr6ocrIwWC+M8qgauX0j4RBU/3SBFIAQQhCfMkfGmLRd1+FFj+dVJdK25PHnXkmndDOwmAfiT764n9HkkePl9kXLBfAUJClWOrp7ht948Vu3XHXamhocAFJ6mk4k8DCBUnptjfHNmwbePLAX6khiADAgcM7Wq4nFtxffqYQQsLO9qxqFqvEOISQhkFD4WUJKCXRFOJ5JVMB4oj45Ozvra8nlos6Mf/iSK3fPDPVfchlz8dat2wxTXbFsqU6N3/z65+edt34kNdNYH68NakBw4SAHo5BXyI3v/qcvf2N5/2kUYUMPNNUn+7vaELGJQQ4cPqaC8IO/+EVjRzuAVHLwtqqRc04pnSv1FEU5VcYxDjGSFFMBJAZtZ60auPo9x8aOnvfla8983zml6SkhhAch59yPepRSnWofueZ6rSkycO4m6jGnUqqtrR05MqiriLszlexYbSx+YP+hSNDUKECIhpNmrD4wMrmrpgEkm5JYUs+VriePj0786fltkbqGzHR+1aKli5e2fO/b/3bBxrMLmXEMOXMYxkUgmG82iqL4zgMAgD1dixBCrusqigKFFBhCCF0M6pZ17njp2YtvvWF2eKwhWZfatmfwTy/XNbW5XNQk63O5HPCrS6jQSuGjH726e/WG3+waXL5kUVClCpQcQuQVEeRQU4ouGjx6/PCRE5oRGzsydMWHLgtYw2OvnLjt219fv/E027allAAg5nqmDlaftsjQlZpEbdbKhSLGVDrFmfG979zf1d0ORRQQxy8K/bDped5cbPGNDFECAEBcNi/vXXr5O6+545YgQ+293aFkTcPG0/IGqgCOMZ6envbthxCiqKWzLli0dEMkA4pNCT1KXVZOm9FosTwNKVLCsX2Hx81gcvGyM6dS+Xdu7L9myyoaKBu19eP58W99++u5XE7TNAihBB7VQNGBT23d/9KeA2rA6+yJYmonk7WrTlvU2V33wSsuOHBoRzXh+lZDCIHdnT1gvmKrhlvHcfSwkdXF+Ve836irmS3nTNWIC/izj3/+xi3XLOlb/pHrPxNeuTiEDFHmbX30c9ddOjjDZWxJqKxkODk2mupJ1vzx+e2pdHH9qtUHDuy88dOfZMWsKxwKkI1QYabAJvNf/NxHk92N4WjEK1UgxipAAjHInU1nrWlsDZihaLFiR+M1XtmanjzuOUo8vvSGm27v6emZz7aQcw67O3sWlhLVUCUZ5+XiRHbiI3d8Jd9WryJFyMLykUzd8UlHcs/xJrL2PY89mehsEQ4n0AU91Oxaf+Ol/2/by/s9hvv7lsymx9tbkhqAjAkiIUS0DCUAoiTsxw5s/dNd3z6rdbnrsrQOVpx/1m/+9Z7Vi3s3DixragqrAcI5r6upzWQyuq4jqD9w74+PDaf0cDNG6oLEhaWUSMyPuYQlAUIIIFhIT9358at/tOWDZ87mB4Ymk6NjzcemjWzZrK3VjEQwHFq/om/WLSJMjVAwXtsoUeNd//glzyrP5LPL1w5MnJzs61lJBfGYjrEuMfXU0mvDO1FjUFZKMU6AIyuMuRRGlnZNxwPr3/+e6NL2VyuZCsVNkWSyucXlYnx0uFLM5q3Jd1yw6YbPf/roycNIAs/zhBAQztUmsKuju1pKQIyAkAAggtgXtlwexxIxgTFmQiAFCQQhF9DjXJQdxigO/uTZZ57YvXvl4pWaohegOxZz3/vei/JHUhuT6+t7umJxNnIsi9Q9odqV+RkaiU88/+qLzz17woB6dnwqEgrnKk5y42msOcENA7tCQpxg7nnNGreKqjR1CStWhqgkny/98omnXn7pjd7FK00Vc09AiDnnjDFCyFsrJCGRBAICxCXPFjWiCIIEgk6pjG0GXAYhlAhKBDHGvGyfvWYdALgCpAyalm3HD4GHv/TjfY/u+P5995Unsyf2pcYHZ7504zfKhT1NzcM//dGD2x4+hIpcMF4mNLFu7eJNmywBsWYghBVFAQHT0rW7n3juPw8OkQTEukUWN919YM+zLL9z6xvXXv+h6BXn7D6yD0Dmli0OuL9NJXDBGYQQghIKgPQQ+e22F2/a8oGRY2/WtzXShAElUf05GAiJDCFFUIsCpFGlDCRRyJ+e2br15edr4vFyyQIeeP6Jx+778X8s6u3q6rvgI9d+7+z16/IZBFWTQ7emvbWia+ODxw3FyCie1tkIFQIhVIQjMW5dc44KRNFFsK7929v2x7o2ljA45zt3HJEsQoNBpAAAiEIRpXbZQf62cuFgUkgpVVVNlSsnrGJTZ7fwXMghRAAAICFAlCCJi2ULqfCeH95XLrmJaO3tX//Wnr1762uThBBCVAjhxe/92OLlZ6xcteyDl7+/s3/1My/t7mrraFzUC1XVRVRADUuYy2YzsLJI1csISAiRH90p9Rj79xf2xGojwaYuaNsIKp7DFS5Kg4fskm0aoWKxzFxOKXVdFy7q7q3WetUSGkIIIA4A2QzYNRdfZBdLdU11UCEMAYEg9ioEgMNvDiWbuvnyAQ+i2tYmqMNgMDo4ODg6OrpixQqvVLr88svXrVvrMWfTuZsP7d25Z+f2dZvehRTNsgr53GzqxMlsprT5mg8OOTmtvV4gqMwfIhFIGGRQQmBjF+SgQ2xXJiB7+a67G+qbCFZcl/lOLISAixctWViHnmIAQcRhxHWu3/KB9qgiccCBzIEuwEgHai6X03Xddd3XU5nnporTE5Nfu/OroXB8+/btAwMD2Wx217OPTM9k1mzY2NDaDjEqFovRaNTzvEg4MT09NT4xCqH41DXXhhL1n7jhc384ur/5jH4DafMnLgJJRQrhuC4THAoedbyHvnLrxr7+WctTFIUx5p9KSCnn8gAhxN8i+UnN8zyNKhwBRkGNADdftoVqEEsBKGQUYDEXfB3HETDy3d2vN7Y0Xn7ppZLzcrkcDofz+bymYgRJLFGTzRdqE9Hp6WnXdXVdN83A+PikpmlSShe6p61aNTCwrv/MjSmX9Zy9MuPlXUIEIEEMi8Wi5klvNrv70cfxscn+1i4LuH60ny/skBAC9vYsrlbb1V2LEAIAQSGSgHIoPcrveN97NdcLhUwRUAAU/p5ICPG1+34Z2nyRoetbLnhXyDTy+XwgEFBVtZQrhCPBQi4bj8ZsITBVLMsyDMO2i7puME/atqth6XqpRx//7XNbX4zXNCxeXNPSmzx4dPj3v3+hNFUEHu/vXBxnxAgEhmbTQNUxpAiK6r7K8zgA4FQmru4qqxtQJOeKWIRQ3Kvccf1HytAxoeEB1+YggkiZsp+MlF+bmG3pWdxC5CMP3PPHP/7ZsT3Opa9l/yzV34jW1dWNjIwYWgCq3LFlbQw/+vPrl65cPjU23NncWg417N61Izc8BWbV5c2r2tQQ8YCKNImRXSmVpDCaaj9642fTOm3s7FKQhjlymCulhD1dixaeyfkPflpwXVfTNM/jQghrduqOz/1jkkChSEPVpIAjB48HO1p+ZUMzUTc9NdNdE7nwjAFKVeYJTQtYluU7iaIoqqrati2EcF1XeoxjHotHHrr/C5s29lGsZu3RgpPND3n1RcMsmDFcRxXV1YASN1/eu4vqSld3p5q1iSPTZcvsX3zdV2+ZyBYWtXd7HAoh/goDAkhNRxC577/sIl3Xbr/zTkINz1YbjNCnN5+XaI/U6AkFMl4B//zD+zs/9amaUKxBp93d3aFI2HVdwYFhBEtWmUPAShWVqkhRbacsJQMAlQsWMQNuabbJfG18fGfCrOECpoZAdKqGCrzrxMldMweWb+zXI5GpfKZSTBfSUwrQ3TxvwbVX9L1rbGJoCNj/9NN7vArr7F4upST+MZtvRRhAANBEceS2265X8Oyajlh6cvCX918TMOtmy6GPffzO6+65t7+ltb1LXbqsJlyDA73Ha0af+NTN9x44NGwG1JBSGZmcUqghAWzQNGHkRkafffrlx96/5bNTY1nPc4ZO7tL1fCRckytYdh2qT7RP51L5w/m28goRjqurT1/jgqN//EFP/8bBN/c+/POfrlu5opjLQ+RFw02HvSM/O+y8o2N9nx2KMJyGLJWaDIVCc+V0tRySqnv3j79ItPzO7S+evXYDZSXhOlxCSSvjk4mrt3zlK5+5zIWTZigKuCIqILGypaOjLmVZeHIIYDegBz0XaKp5+PXtLc3tgZJJ4y1SDc5MZkqlEpdFzr1KZXZgoDdfKlbsYrii07Egom0HjdREISBg5+rTFxW9SSNuFSYzRw4eP+8dFz75xAtvHh60Tm7b8vHLsq+Mr0B1RaB84mc/cF23t7eXeMgjECEGCKIaUieLJ2s1a+TVN87uW63aeYDKECkYSIQxJZVlK5uXnrW4MdmJJYUeJwIwLmAlhXRl76izbm07wQZWrCNvHDmxJ61EOxvrkxUvGtOian0QV1xdx4oSKaePI1lWcXl4eOj1KafFWNndALuSwU7QIoy1kc7mXz/6PD8xQ5xk16JL3pzOd3f2t2lLfjd5cv/Tr7bVJGkgClJlaDtYkZVKkRBmQAwEqBDgxgh45F/udw/Y48cyPUuDJYgAQAhzVonz7FmmyN98Q2d/L8rnU9ArIsg4ARhQKWEwGHz66adXrP//vJCDbMag9ad97H3LzvnQ+DBQg7kMK2V3vPDIA3de9aEP53ITCtae3rZnybJwtK6rrt4j40V9MBWcijj2sCOGuq64Ym3zyp7x0gQEU9GE+sYMoiLRlD3jAxekrdKJ8VQvIJqiIiHndoVIljkHHgaVfKk4lt2250B/f8/a8zbP4pM43yidVoBKxWw4pMc1bASVhvThCSNuScQtJfjmTG51CFcqXqVU0nVd5NPCY16glXWd1xNo3PHUY+85Y6Mowcf27V/Xc5b9j+GmTvMXd966+rTz16zYbOVfrE9QJgOpE1aS6swpYCZjKk098qsul9kSQVXHr+e1uOxMWuVCVoXdZgM68/QO+7HnrfxkvK1pcmqMEEI4RFJKVWIYjqCwePCpJ/OPPDrrlf/t9lvra+qtQljBqk4sqB8KQFeYUlUz0HBsm2jFky1N9cW8Q0nOsYxKKeNmrVnHHldXt0bi26ffGDw6XnDzs8UC0WpPHnxsZceaomN86ou3v/yHX4+lormUI4BVE2wr5jM4BnResTWt7FSASwhBbinVFWypnTrqjnm5fWBEaX0tM3zmxy565dVd63U1r/LZqSnmSdflpJp6IYQcoOF0Aaj28o3NiZ7y9LHjicCmcjFLzSkS3TdaKXVqQIExp1SYNo2TM3AxkvUJYzbTkXptHOW9ctles+aTsRMCH0nVELJu8Rn50qQSrZWyEjSXxQIGk04pr592/ntfeuqZPduG2uqvHB89rLpMjxj5DFMlUBRSLhcjkYTrmo7jCOkhisOa0mkd/EI8mv3RLxNmYMazbv3Jj0h9tBZTzjnsbO/yQ9DcuSdkG85ftf49S+pMoBXbQHE1QFORptfzoTyR0Uhl+PlyYk3UyBfSFTXSKk4cOESnnRYyns6lt3YPdMSWX5BELgSaElAZio1PHl3Zu9RjJSsfK1gpormuU87xSDRLc2PDo6XyEiXAB2cCWJPBooID2dxsJGrm83kENU1TyuUiw8IRbo0VTyP58Xv+2W6IOlnbDARVU8MYSwlRtfz0N8aecJGCoomkgrgRKQQanjAbXmTMUxkcTU2+Nl5o14RTKidM2azOilADUJp2b3vF8ZxQ4vSejXcotPvN2egs780oy7LlRNGNjXmtJwtdORKcdPUntqdx+JzXXsuGlqy97w/PaGb9IDLfrAsdUPNFTcVGwHGZdEFINVUVV5wi1U3uabxIxiPy2gdvGzj/dGvWStQ2BSN1BAcgUAVHpy6hIIQAQBoxEVT3PXOic02NEpwlNsWKLvRRw4FLQlQJKkVSwQqfzeBctmlwP5cE9a09951nrXz62b18wg7IcKBgv7H/9Y6OVUcO7zGVGDt2KFsqtbe2dcTamefWTojzE/0nHt311etvGRw7EkzWlmL1Koa///PDbfUJqqjb9u4/f8OZXiYfklpUDWbGj6cAv+6bd2++cAMjbvVSGUDgV8Rk4e0iBsLOid/+/JnzzrtoeEIRtLRmg75kUdxQG4olr+wgNbLiaIoNT8LWpsadLz9z8cCmiUy2tbNnx97h1w4fPXv56Y/s2HnxinVDhUB5amjowPGly5XO1qajE3xJ/+LJ1HTzQN/2iRPdK5bTovmdx+6Jp+Ca9RtnvfJQfip8dn+krhHlvJrTzswYZi6bdguTjz3wQGs4vGhFry5BPJpIlbMIAyEEoYgLNndl0drctvAWyPXEue+6xOMiHo1hjNPZjKmpUTPEJCiVyx0r+2raW3ceexYGFJ0qIazBrIBCDh46olJ646c+fWh6ui2EDp0YW7Nq7d59r9ve1PqBC8YzJ/LpqWSsMWjGBo/tDcMSy+WUuvbnd7zuEupQ2LhkEUMg9eZopIx7mrtMM5S3chKjsGIMDw4ePXo4VhP84b/f3RCP7D86ZASCiUQtYy6EGAAAG+obq/c/jLFbb79rx4GhoGGUc2nDCAawp6gwEFa1UMxzgRY13zhxGCRUM5zgBCFFTJ0cDynKyIFDBgA3ffQiZtNsYbazbfXQ0Mnf/XzHdCpdKAEkEqMn961aE7juCxfWxo03j47WtS/dvfP4kCErnNc1tATDMUjoqy9s61QTy5p6tECwWMhSTXdcV3IYoGomP1vITp84dPB3v3soNTOq60pNIokQ4ZwjTBQAEAAASo6AyOUtMxQWQrQ2Nuiasrh/zf0/e2T37pOuq1ll7pRgX+uq+kSrTgO6VKzJUnPvCg+Z5111RSWAeO2mYNe7t+8rFmfiDbFFP3jwm/f+8gHHqz934zmLepdNTZlfuO7RLefef8vt+5+aig03RvR4rK1nSSAUERIrgFYAV5sjFWZbVgkjJZ8rMClLXmUiPQUpbersXbJ+4/U3fS0YMIlwUzNTXFQk8BCQnBAkJBRYFVS/+7t36RSeuX5jpKYxGAkPj41ecfVVyaZGw1RraqKYSMNUK45nO57jMSMUbgwnF3cvGZvIb9pw5VXv/iBVlCMlZ7o58XRBOfuCr9yw5R4vD5/ZflCazZ7auGTthZd+8dZQknbXudMlK4/pifTU0cnRo1MnUpV0c2d7zimH6hKBSMgTXAvodqlcLlicS4zpzEzaskonx8Y7lq9ykMqRmDtg7GppY4JzpKwc2ICwEtBDhCBPuEY4smZgwK+0U6mUlSkt7+/L5vOmaY6ouZxVIAp1GYMV1N3VPj1uPfOdRx999LtTE2D3zh2//9VDI8NHPK6Xba6rbiwRDUViP/zBd//h4k9z01p6zhLcoOgJo6mhwXVtyypkc2lKaTiWLE2klgaaXQ9n85m6eCKbzpStsmqEKpUKQkhRlMmRIZ3C79391bCOiRFQFA22NjZwIIWg8USyd1kforoeoMuXrbaKDjSVhvrkzh2vJOvqArq5pKf79ttu2bV9q9lc/6FbvsI1DTLXA0rJKo8/c+A/v/+vV15ys2VZtmPZbhryyCt7HszZ4Bt3fweTSGoon0vNVNiR1e9fVt/TYzmISDoxPZzsSM7kppuampiDjh85Imdm37XhPcUCn5weEUyG9KDHBUeokM8VMjPp2enHf3OvBLamaUEzNncH3trYxKVkQmq6HknUL+07E2LVCEcUlTC7xF1PIRQAYHPHoPq937tNwRZWQjSS0LnSGgjXR8SeEaWmrqev7/y9r+5xvSJVnVVr2g7szcVicSmVSLQxMzs7MzYZNmlFpGHIdB3Z0lD/5Vs+fsWH33vO5ZstnWlhLaoFv/XJz8Yg+dF/PDRelumpaSnE5Ngo57yQz48MHdz/6tZokGINUxIQHAEgfAYIkAhCQQi0nWJq4kR6InPhJZcD5mTyKVbxgJQaVcyA8cdf/Xw6M6hqoL5xKfCckmQC5m3gBrSegE5XDPRccdnG7EymUMidGNl/7723LOq4VlOigMuJ4QOOK9ZvWDk0svXxx+/5wDs/rbu6PVXau2t3AOgBoE+lT6YnS/c/+MuQcHFQXnHlhQ313Z7AM6nJutq4XS6EdCgEaqitkRJKxJkHEWYAOpJRjDFsaWquXscCAIAQAAc6evrbOroqJcsIhBhjufzMru1P2I4FIYqEaxdeHhMb6cGOdBEu6m0PqO3ZqZxVGrr6Ex966CdPAhF0bLZ0Wdfo5DjQhx/48f2XXfrJfGqqrXa1poRRaCaTGVca8dp3r1qxoj8EtPe9Yx2BzJOiqbmD2aeOT8R8zqruHOX8AADAxmTDPHIBIcRgrssCYCQEkAJBCDERjAlCBZAISAqRWLCWTqDR271mbHLqru9+4+bPfJdXHIQ1ncbLRZjNZmvqAi19LoZNh97YqUIzIJtt7vYu737ppT8/v/3Xn7/1y++78n0lu2LN5P7l5usq+VGMMVUihmEsuHKfI/e2RoLqCRCqNhlIKTkCTAoOOOceAAwiF2FPAo8QBCSREkogFg4InQDIaLm9Tnr8iWe3SUYpN1WSCJpN8UQyGIpCqM8MhV56+jlNxlXYY5q1hmluvuRMNcReOfjaqrMHnnrhuUWLe+qbGwdOf0cgaALJi4UMJlJKXj2wmqcFq4Kvlj+EMSCloFT3eZWSAzx3QvrW7qKqTt/Su8YgLLtF1XHPaKw/+cRD7T1ncBrD04ZAuuNakWiwXKpAT+lsW5Mtpdaf3f3cY89DFZZKJVWjmEIA2dUfvrJg5S697JJd2185e+AXUEJIoOu6CJL5PgMh3towBxZ04yEuKowXK3bWdnIV2/IPDKvX3f69vt+o47uK38vg5weMMRROBShZW8DKbKytpXtp55du+iQzc6XKtCfSiJQUlULKHFz+/B03PvToD1044sl0upAZnx7XtECl7B07etJ1+baXd7x+8FDZQRxiiKFt29XmCPAXw4c0B8MI0AXl9Fv6hQB4+zf+bf7CbkhHSgpQm2H2xSP7xt2KkozVrAiIkAcKl1x2+e/+8GdRYaqhf/L6a2+65TOhcKKtoWv/3r3x2uAd3795+66Xzzx30/j0VDgcdkvO8aPHLn73ur7eFiwFEFDX9Xk3ONVOWT19OwW4ysBfG6c6VxZ2sbxFKhBzBMJSrq1NNJICV2OjFW24ABOtKwePja9bv3n/wZPhsLpp0+k7d7wouTx2+Km1rVRxrJvue7igBiuC5cpFz/M0RLZcchECRSwZxVTKhRT/Zj/f/4CBhaAXMoMBdjAgnr2hvj6qaxHIDJUUEUnlnHi47qW9B4AWCYWwcOy4Ga0JhYJBz7PzCNOJvDfqyGOpSYElhFCjmiNchDn3OJAYQjRPRQL4dgf4+wz8Vcv7q0NAzCFSuNsVCS/VlYCuaARTAjAJIEIAgojgqvMw13MlZxW34IpJ5r0xm3G4qB7uvwXWwt69v/H9XDj6S+j/ffQAACQ5kQwgPJzPbh2eOlZiXjBalIhBG2IXIVdFTAFIekKlqkCowNw8pcOefWAy5fC5UPF3sb4N3kKQb9fA/wg9AAABBgCREAkkpSdMPQA9DrmQGAEhFYQBAFAyiaAHpSeFSjTbZR7wFJXYFfdvLQvnW/D+LgAY0N9+Ufm/GwghKk61WwOxoGsPAjAvPA6kqMpxQWL6XzPwf0Uv55tGpZQCQiGFlBIBiSQA85GEz+dOIaUApw5BxHxo/kug1VTzdwH8XzWwkAacZwYAIMDfp/023G/9+N+15P8CyuP+huihU40AAAAASUVORK5CYII=","text/plain":["<PIL.Image.Image image mode=RGB size=64x64>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["img, label = image_dataset[50]\n","print(f'{label=}')\n","transforms.functional.to_pil_image(img)"]},{"cell_type":"markdown","metadata":{"id":"SR0BEQ38Err4"},"source":["# Procedure:\n","\n","1. Download pretrained Resnet18 model from torchhub\n","2. Modify the model for object 101 dataset subset (The dataset has 101 distinct classes).\n","3. Split the dataset between training and validation set (80% / 20%).\n","4. Fine tune the model for classification on the dataset.\n","5. Output the fine tuned model's overall accuracy on the validation set.\n","6. Find a way to show label wise performance/accuracy of the finetuned model."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1704717137606,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"3qqFuPd8GgHE"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import math"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1704717137606,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"o4F6Qyv2G04w"},"outputs":[],"source":["batch_sz = 64\n","number_of_samples = len(image_dataset)\n","train_set, val_set = torch.utils.data.random_split(image_dataset, [math.ceil(0.8*number_of_samples), math.floor(int(0.2*number_of_samples))])\n","train_loader = DataLoader(train_set, batch_size = batch_sz)\n","test_loader = DataLoader(val_set, batch_size = batch_sz)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1704717137980,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"2gVlkaNtEGox","outputId":"f4a7e98f-b7d2-4327-8464-bd03941fc9be"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]}],"source":["model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n","\n","# Freeze all layers in the network\n","for param in model.parameters():\n","    param.requires_grad = False # Freezed then unfreezed\n","\n","# Replace the last fully connected layer\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 102)\n","\n","# Unfreeze parameters of the last layer\n","for param in model.fc.parameters():\n","    param.requires_grad = True"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1704717178282,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"1R34vnHhGi31","outputId":"b371a327-d93f-46ff-feef-4630fcbfd5b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device cuda:0\n"]}],"source":["device = \"cuda:0\"\n","num_epochs = 10\n","lr = 1e-3\n","\n","train_losses = []\n","val_losses = []\n","lebels_corr = [0 for i in range(102)]\n","lebels_len = [0 for i in range(102)]\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss()  # multi-class\n","\n","model = model.to(device)\n","print(f'Using device {device}')"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":206234,"status":"ok","timestamp":1704717386027,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"fOWyJXxlGsbF","outputId":"ea52a45e-6e6a-4aaf-f146-1981d088afd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0, train_loss=1.7284649056512322, val_loss=1.863946696079012. labelled 1034/1828 correctly (56.564551422319475% accuracy)\n","Epoch: 1, train_loss=1.2469572583595347, val_loss=1.775709326470707. labelled 1073/1828 correctly (58.69803063457331% accuracy)\n","Epoch: 2, train_loss=1.0168968306140471, val_loss=1.746330837191325. labelled 1077/1828 correctly (58.91684901531728% accuracy)\n","Epoch: 3, train_loss=0.8586525508717411, val_loss=1.7434090553279518. labelled 1083/1828 correctly (59.245076586433264% accuracy)\n","Epoch: 4, train_loss=0.7402757627022859, val_loss=1.7535188618061057. labelled 1095/1828 correctly (59.901531728665205% accuracy)\n","Epoch: 5, train_loss=0.6472510482572088, val_loss=1.7727119901769792. labelled 1097/1828 correctly (60.0109409190372% accuracy)\n","Epoch: 6, train_loss=0.5717412129476332, val_loss=1.7977849897201004. labelled 1101/1828 correctly (60.22975929978118% accuracy)\n","Epoch: 7, train_loss=0.5090468773845442, val_loss=1.826267539541883. labelled 1093/1828 correctly (59.79212253829321% accuracy)\n","Epoch: 8, train_loss=0.4560403850249347, val_loss=1.8566483501793258. labelled 1096/1828 correctly (59.95623632385121% accuracy)\n","Epoch: 9, train_loss=0.410601297653132, val_loss=1.8880829226788076. labelled 1096/1828 correctly (59.95623632385121% accuracy)\n","Training complete on device cuda:0. Change device variable and run again to see the difference.\n","CPU times: user 3min 16s, sys: 8.51 s, total: 3min 25s\n","Wall time: 3min 26s\n"]}],"source":["%%time\n","for epoch_no in range(num_epochs):\n","\n","  #  training\n","  model.train()  # convert to train model. This turns out train-specific layers in the model (if you dont know about them, an example of them is dropout. more on this later)\n","\n","  epoch_weighted_loss = 0\n","  for batch in train_loader:\n","    batch_X, batch_y = batch[0].to(device), batch[1].to(device)\n","    batch_y_probs = model(batch_X)\n","\n","    loss = criterion(batch_y_probs,batch_y)\n","\n","    optimizer.zero_grad()  # need to clear out gradients from previous batch\n","    loss.backward()  # calculate new gradients\n","    optimizer.step()  # update weights\n","\n","    epoch_weighted_loss += (len(batch_y)*loss.item())\n","\n","  epoch_loss = epoch_weighted_loss/len(train_loader.dataset)\n","  train_losses.append(epoch_loss)    # add loss for tracking. we'll visualize the loss trajectory later\n","\n","  # testing\n","  model.eval()  # take model to evaluation mode. turn off train-only layers\n","  correctly_labelled = 0\n","\n","  with torch.no_grad():  # this makes our model to NOT track gradients\n","\n","    val_epoch_weighted_loss = 0\n","\n","    for batch in test_loader:\n","\n","      val_batch_X, val_batch_y = batch[0].to(device), batch[1].to(device)  # convert to [N, 28*28] shape where N is batch_size\n","\n","\n","      val_batch_y_probs = model(val_batch_X)\n","\n","      loss = criterion(val_batch_y_probs, val_batch_y)\n","      val_epoch_weighted_loss += (len(val_batch_y)*loss.item())\n","\n","      val_batch_y_pred = val_batch_y_probs.argmax(dim=1)  # convert probailities to labels by picking the label (index) with the highest prob\n","      # dim = 1 because we will apply it to only one sample for all features and take the maximum likelyhood\n","\n","      correctly_labelled += (val_batch_y_pred == val_batch_y).sum().item()  # item converts tensor to float/int/list\n","      expected = val_batch_y_pred.tolist()\n","      actual = val_batch_y.tolist()\n","      for e, a in zip(expected, actual):\n","        lebels_len[e] += 1\n","        if e == a:\n","          lebels_corr[e]+=1\n","\n","  val_epoch_loss = val_epoch_weighted_loss/len(test_loader.dataset)\n","  val_losses.append(val_epoch_loss)\n","\n","\n","  print(f'Epoch: {epoch_no}, train_loss={epoch_loss}, val_loss={val_epoch_loss}. labelled {correctly_labelled}/{len(test_loader.dataset)} correctly ({correctly_labelled/len(test_loader.dataset)*100}% accuracy)')\n","\n","print(f'Training complete on device {device}. Change device variable and run again to see the difference.')\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1704717420268,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"tcQXz9yMGvOz","outputId":"8a0ac24a-4bf4-44cb-f57e-6eb59f20b857"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label: 0 accuracy = 34.77917981072555%\n","Label: 1 accuracy = 95.15279241306638%\n","Label: 2 accuracy = 89.77955911823648%\n","Label: 3 accuracy = 63.78896882494005%\n","Label: 4 accuracy = 85.11979823455233%\n","Label: 5 accuracy = 54.94505494505494%\n","Label: 6 accuracy = 69.64782205746062%\n","Label: 7 accuracy = 0.0%\n","Label: 8 accuracy = 0.0%\n","Label: 9 accuracy = 46.49122807017544%\n","Label: 10 accuracy = 0.0%\n","Label: 11 accuracy = 34.21052631578947%\n","Label: 12 accuracy = 56.666666666666664%\n","Label: 13 accuracy = 56.630824372759854%\n","Label: 14 accuracy = 46.391752577319586%\n","Label: 15 accuracy = 13.698630136986301%\n","Label: 16 accuracy = 47.87234042553192%\n","Label: 17 accuracy = 65.38461538461539%\n","Label: 18 accuracy = 39.705882352941174%\n","Label: 19 accuracy = 16.49484536082474%\n","Label: 20 accuracy = 95.89041095890411%\n","Label: 21 accuracy = 43.54838709677419%\n","Label: 22 accuracy = 85.18518518518519%\n","Label: 23 accuracy = 18.96551724137931%\n","Label: 24 accuracy = 33.83233532934132%\n","Label: 25 accuracy = 47.82608695652174%\n","Label: 26 accuracy = 58.98876404494382%\n","Label: 27 accuracy = 18.181818181818183%\n","Label: 28 accuracy = 14.583333333333334%\n","Label: 29 accuracy = 24.752475247524753%\n","Label: 30 accuracy = 19.444444444444443%\n","Label: 31 accuracy = 44.11764705882353%\n","Label: 32 accuracy = 75.26881720430107%\n","Label: 33 accuracy = 70.8029197080292%\n","Label: 34 accuracy = 11.11111111111111%\n","Label: 35 accuracy = 14.018691588785046%\n","Label: 36 accuracy = 31.52173913043478%\n","Label: 37 accuracy = 38.732394366197184%\n","Label: 38 accuracy = 19.897959183673468%\n","Label: 39 accuracy = 100.0%\n","Label: 40 accuracy = 47.66355140186916%\n","Label: 41 accuracy = 62.121212121212125%\n","Label: 42 accuracy = 28.244274809160306%\n","Label: 43 accuracy = 49.65034965034965%\n","Label: 44 accuracy = 80.76923076923077%\n","Label: 45 accuracy = 27.027027027027028%\n","Label: 46 accuracy = 45.205479452054796%\n","Label: 47 accuracy = 64.04494382022472%\n","Label: 48 accuracy = 27.002288329519452%\n","Label: 49 accuracy = 85.71428571428571%\n","Label: 50 accuracy = 27.272727272727273%\n","Label: 51 accuracy = 69.14893617021276%\n","Label: 52 accuracy = 29.591836734693878%\n","Label: 53 accuracy = 100.0%\n","Label: 54 accuracy = 50.0%\n","Label: 55 accuracy = 29.288702928870293%\n","Label: 56 accuracy = 63.46153846153846%\n","Label: 57 accuracy = 52.63157894736842%\n","Label: 58 accuracy = 77.61194029850746%\n","Label: 59 accuracy = 18.085106382978722%\n","Label: 60 accuracy = 17.54385964912281%\n","Label: 61 accuracy = 74.6268656716418%\n","Label: 62 accuracy = 48.0%\n","Label: 63 accuracy = 15.517241379310345%\n","Label: 64 accuracy = 80.54054054054055%\n","Label: 65 accuracy = 100.0%\n","Label: 66 accuracy = 89.70588235294117%\n","Label: 67 accuracy = 52.577319587628864%\n","Label: 68 accuracy = 34.78260869565217%\n","Label: 69 accuracy = 36.61971830985915%\n","Label: 70 accuracy = 75.96153846153847%\n","Label: 71 accuracy = 50.0%\n","Label: 72 accuracy = 26.08695652173913%\n","Label: 73 accuracy = 73.07692307692308%\n","Label: 74 accuracy = 0.0%\n","Label: 75 accuracy = 58.47457627118644%\n","Label: 76 accuracy = 58.064516129032256%\n","Label: 77 accuracy = 39.53488372093023%\n","Label: 78 accuracy = 61.904761904761905%\n","Label: 79 accuracy = 69.56521739130434%\n","Label: 80 accuracy = 36.111111111111114%\n","Label: 81 accuracy = 29.032258064516128%\n","Label: 82 accuracy = 29.530201342281877%\n","Label: 83 accuracy = 12.5%\n","Label: 84 accuracy = 100.0%\n","Label: 85 accuracy = 68.125%\n","Label: 86 accuracy = 34.96503496503497%\n","Label: 87 accuracy = 39.784946236559136%\n","Label: 88 accuracy = 25.96685082872928%\n","Label: 89 accuracy = 98.9010989010989%\n","Label: 90 accuracy = 56.14035087719298%\n","Label: 91 accuracy = 81.0126582278481%\n","Label: 92 accuracy = 47.05882352941177%\n","Label: 93 accuracy = 80.8411214953271%\n","Label: 94 accuracy = 76.5625%\n","Label: 95 accuracy = 66.88741721854305%\n","Label: 96 accuracy = 17.21311475409836%\n","Label: 97 accuracy = 14.705882352941176%\n","Label: 98 accuracy = 0.0%\n","Label: 99 accuracy = 62.93706293706294%\n","Label: 100 accuracy = 48.484848484848484%\n","Label: 101 accuracy = 79.81651376146789%\n"]}],"source":["for i in range(len(lebels_corr)):\n","  if lebels_len[i] != 0:\n","    print(f\"Label: {i} accuracy = {lebels_corr[i]*100/(lebels_len[i])}%\")\n","  else:\n","    print(f\"Label: {i} has not been included in the testing set\")"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1704717154738,"user":{"displayName":"Fadel Alobaidi","userId":"13630301037386227030"},"user_tz":-180},"id":"4IxPz_2TDZcK"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
